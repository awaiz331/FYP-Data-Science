# -*- coding: utf-8 -*-
"""custom_model_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13xQ8aCRBA6YldNKXdaNL29hGVCDKDzvU
"""

import os
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, confusion_matrix, classification_report
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from tensorflow.keras import layers, models, regularizers
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping

# === CONFIG ===
IMG_SIZE = (224, 224)
BATCH_SIZE = 16
SEED = 42
EPOCHS = 50

# === STEP 1: DOWNLOAD AND EXTRACT DATA FROM KAGGLE ===
!pip install -q kaggle
from google.colab import files
uploaded = files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d anasmohammedtahir/covidqu
!unzip -q covidqu.zip -d covidqu_data
!rm covidqu.zip

# === SEVERITY CALCULATION FUNCTIONS ===
def infection_percentage(lung_mask_path, infection_mask_path):
    """Calculate infection percentage relative to lung area."""
    lung_mask = cv2.imread(lung_mask_path, cv2.IMREAD_GRAYSCALE)
    infection_mask = cv2.imread(infection_mask_path, cv2.IMREAD_GRAYSCALE)

    if lung_mask is None or infection_mask is None:
        return 0.0

    lung_area = np.sum(lung_mask > 0)
    infection_area = np.sum(infection_mask > 0)

    if lung_area == 0:
        return 0.0

    return (infection_area / lung_area) * 100

def classify_severity(score):
    """Convert severity % to category."""
    if score < 10:
        return "Mild"
    elif score < 25:
        return "Moderate"
    elif score < 50:
        return "Severe"
    else:
        return "Critical"

# === BUILD DATAFRAME WITH SEVERITY SCORES ===
base_path = 'covidqu_data'
lung_base = os.path.join(base_path, 'Lung Segmentation Data', 'Lung Segmentation Data')
infection_base = os.path.join(base_path, 'Infection Segmentation Data', 'Infection Segmentation Data')

def build_verified_dataset():
    samples = []
    for subset in ['Train', 'Test', 'Val']:
        for class_name in ['COVID-19', 'Non-COVID', 'Normal']:
            img_dir = os.path.join(lung_base, subset, class_name, 'images')
            lung_mask_path = os.path.join(lung_base, subset, class_name, 'lung masks')
            infection_mask_path = os.path.join(infection_base, subset, class_name, 'infection masks')
            if not os.path.exists(img_dir):
                continue
            for img_file in os.listdir(img_dir):
                base = os.path.splitext(img_file)[0]
                paths = {
                    'original_path': os.path.join(img_dir, img_file),
                    'lung_mask_path': os.path.join(lung_mask_path, base + '.png'),
                    'infection_mask_path': os.path.join(infection_mask_path, base + '.png')
                }
                if all(os.path.exists(p) for p in paths.values()):
                    samples.append({
                        'subset': subset,
                        'class': class_name,
                        **paths
                    })
    return pd.DataFrame(samples)

verified_df = build_verified_dataset()

# Calculate severity scores
severity_scores = []
severity_classes = []

for idx, row in verified_df.iterrows():
    score = infection_percentage(row['lung_mask_path'], row['infection_mask_path'])
    severity_scores.append(score)
    severity_classes.append(classify_severity(score))

verified_df['severity_score'] = severity_scores
verified_df['severity_class'] = severity_classes

# === DATA SPLITTING ===
train_df, test_df = train_test_split(verified_df, test_size=0.2, random_state=SEED,
                                    stratify=verified_df['severity_class'])
train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=SEED,
                                   stratify=train_df['severity_class'])

print(f"Training set size: {len(train_df)}")
print(f"Validation set size: {len(val_df)}")
print(f"Testing set size: {len(test_df)}")

# === DATA GENERATORS ===
# For regression (predicting severity score)
train_datagen = ImageDataGenerator(
    rotation_range=20,
    zoom_range=0.15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    horizontal_flip=True,
    rescale=1./255
)

val_test_datagen = ImageDataGenerator(rescale=1./255)

# Generator for severity score prediction (regression)
def regression_data_generator(dataframe, datagen, batch_size=16, shuffle=True):
    return datagen.flow_from_dataframe(
        dataframe=dataframe,
        x_col='original_path',
        y_col='severity_score',  # Use severity_score for regression
        target_size=IMG_SIZE,
        batch_size=batch_size,
        class_mode='raw',  # Use 'raw' for regression
        seed=SEED,
        shuffle=shuffle
    )

train_reg_generator = regression_data_generator(train_df, train_datagen, BATCH_SIZE)
val_reg_generator = regression_data_generator(val_df, val_test_datagen, BATCH_SIZE)
test_reg_generator = regression_data_generator(test_df, val_test_datagen, BATCH_SIZE, shuffle=False)

# === IMPROVED MODEL ARCHITECTURE ===
def create_severity_regression_model():
    model = models.Sequential([
        # First convolutional block
        layers.Conv2D(32, (3, 3), activation='relu', padding='same',
                     input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),

        # Second convolutional block
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),

        # Third convolutional block
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),

        # Fourth convolutional block
        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),

        # Global Average Pooling instead of Flatten
        layers.GlobalAveragePooling2D(),

        # Dense layers
        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
        layers.BatchNormalization(),
        layers.Dropout(0.5),

        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
        layers.BatchNormalization(),
        layers.Dropout(0.5),

        # Output layer for regression (single neuron)
        layers.Dense(1, activation='linear')  # Linear activation for regression
    ])
    return model

# Create and compile model
model = create_severity_regression_model()

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='mse',  # Mean Squared Error for regression
    metrics=['mae', 'mse']  # Track MAE and MSE
)

model.summary()

# === TRAINING ===
# Use absolute paths for Colab
model_checkpoint_path = "/content/custom_best_severity_model.keras"

callbacks = [
    ModelCheckpoint(model_checkpoint_path,
                   save_best_only=True,
                   monitor="val_mae",
                   mode='min',
                   save_weights_only=False),  # Save entire model, not just weights
    ReduceLROnPlateau(monitor='val_mae', factor=0.5, patience=8, min_lr=1e-7, verbose=1),
    EarlyStopping(monitor='val_mae', patience=15, restore_best_weights=True, verbose=1)
]

print("Starting training...")
print(f"Monitoring validation MAE for early stopping and checkpointing")

history = model.fit(
    train_reg_generator,
    epochs=EPOCHS,
    validation_data=val_reg_generator,
    callbacks=callbacks,
    verbose=1
)

# === EVALUATION ===
# Load best model
# model.load_weights("Custom_best_severity_model.keras")

# Evaluate on test set
test_results = model.evaluate(test_reg_generator)
print(f"Test MSE: {test_results[1]:.4f}, Test MAE: {test_results[2]:.4f}")

# Make predictions
test_predictions = model.predict(test_reg_generator)
true_scores = test_df['severity_score'].values[:len(test_predictions)]

# Calculate additional metrics
mae = mean_absolute_error(true_scores, test_predictions)
mse = mean_squared_error(true_scores, test_predictions)
rmse = np.sqrt(mse)

print(f"\nDetailed Test Results:")
print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")

# Convert predictions to classes for comparison
predicted_classes = [classify_severity(score[0]) for score in test_predictions]
true_classes = test_df['severity_class'].values[:len(test_predictions)]

# Classification report
print("\nClassification Report (based on predicted severity scores):")
print(classification_report(true_classes, predicted_classes))

# Confusion matrix
cm = confusion_matrix(true_classes, predicted_classes,
                     labels=["Mild", "Moderate", "Severe", "Critical"])
class_labels = ["Mild", "Moderate", "Severe", "Critical"]

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
           xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted Severity Class')
plt.ylabel('Actual Severity Class')
plt.title('Confusion Matrix - Severity Classification')
plt.show()

# === PLOTTING RESULTS ===
plt.figure(figsize=(15, 5))

# Plot training history
plt.subplot(1, 3, 1)
plt.plot(history.history['mae'], label='Train MAE')
plt.plot(history.history['val_mae'], label='Val MAE')
plt.title('MAE Progress')
plt.ylabel('MAE')
plt.xlabel('Epoch')
plt.legend()

plt.subplot(1, 3, 2)
plt.plot(history.history['loss'], label='Train Loss (MSE)')
plt.plot(history.history['val_loss'], label='Val Loss (MSE)')
plt.title('MSE Loss Progress')
plt.ylabel('MSE Loss')
plt.xlabel('Epoch')
plt.legend()

# Scatter plot of predictions vs true values
plt.subplot(1, 3, 3)
plt.scatter(true_scores, test_predictions, alpha=0.6)
plt.plot([0, max(true_scores)], [0, max(true_scores)], 'r--')
plt.xlabel('True Severity Scores')
plt.ylabel('Predicted Severity Scores')
plt.title('Predicted vs True Severity Scores')
plt.grid(True)

plt.tight_layout()
plt.show()

# === SAMPLE PREDICTIONS ===
print("\nSample Predictions:")
sample_indices = np.random.choice(len(test_predictions), 10, replace=False)
for idx in sample_indices:
    true_score = true_scores[idx]
    pred_score = test_predictions[idx][0]
    true_class = true_classes[idx]
    pred_class = predicted_classes[idx]

    print(f"True: {true_score:.1f}% ({true_class}) | Pred: {pred_score:.1f}% ({pred_class}) | Error: {abs(true_score-pred_score):.1f}%")